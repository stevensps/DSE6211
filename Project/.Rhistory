nn_model <- keras_model_sequential() %>%
layer_dense(units = 1, input_shape = 3, activation = "linear")
nn_model
nn_model <- keras_model_sequential() %>%
layer_dense(units = 2, input_shape = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
nn_model
nn_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.2),
loss = "mean_squared_error",
metrics = "mean_absolute_error")
nn_model_training <- nn_model %>% fit(x = mtcars_x,
y = mtcars_y,
epochs = 250,
verbose = FALSE)
plot(nn_model_training)
get_weights(nn_model)
prediction1 <- predict(nn_model, array(c(6, 350, 125), dim = c(1, 3)))
print(prediction1)
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction2)
clear_session(free_memory = TRUE
clear_session(free_memory = TRUE)
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction2)
clear_session(free_memory = TRUE)
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction2)
library(reticulate)
library(tensorflow)
library(keras)
install.packages("keras")
library(reticulate)
library(tensorflow)
library(keras)
clear_session(free_memory = TRUE)
use_virtualenv("my_tf_workspace", required = TRUE)
mtcars <- mtcars
mtcars_x <- mtcars[, c("cyl", "disp", "hp")]
mtcars_x <- array(data = unlist(mtcars_x), dim = c(nrow(mtcars), 3),
dimnames = list(rownames(mtcars),
colnames(mtcars_x)))
mtcars_y <- mtcars[, "mpg"]
nn_model <- keras_model_sequential() %>%
layer_dense(units = 1, input_shape = 3, activation = "linear")
nn_model
nn_model <- keras_model_sequential() %>%
layer_dense(units = 2, input_shape = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
nn_model
nn_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.2),
loss = "mean_squared_error",
metrics = "mean_absolute_error")
nn_model_training <- nn_model %>% fit(x = mtcars_x,
y = mtcars_y,
epochs = 250,
verbose = FALSE)
plot(nn_model_training)
get_weights(nn_model)
prediction1 <- predict(nn_model, array(c(6, 350, 125), dim = c(1, 3)))
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction1)
print(prediction2)
clear_session(free_memory = TRUE)
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction2)
library(reticulate)
library(tensorflow)
library(keras)
clear_session(free_memory = TRUE)
use_virtualenv("my_tf_workspace", required = TRUE)
mtcars <- mtcars
mtcars_x <- mtcars[, c("cyl", "disp", "hp")]
mtcars_x <- array(data = unlist(mtcars_x), dim = c(nrow(mtcars), 3),
dimnames = list(rownames(mtcars),
colnames(mtcars_x)))
mtcars_y <- mtcars[, "mpg"]
nn_model <- keras_model_sequential() %>%
layer_dense(units = 1, input_shape = 3, activation = "linear")
nn_model
nn_model <- keras_model_sequential() %>%
layer_dense(units = 4, input_shape = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
nn_model
nn_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.2),
loss = "mean_squared_error",
metrics = "mean_absolute_error")
nn_model_training <- nn_model %>% fit(x = mtcars_x,
y = mtcars_y,
epochs = 250,
verbose = FALSE)
plot(nn_model_training)
get_weights(nn_model)
prediction1 <- predict(nn_model, array(c(6, 350, 125), dim = c(1, 3)))
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction1)
print(prediction2)
clear_session(free_memory = TRUE)
use_virtualenv("my_tf_workspace", required = TRUE)
mtcars <- mtcars
mtcars_x <- mtcars[, c("cyl", "disp", "hp")]
mtcars_x <- array(data = unlist(mtcars_x), dim = c(nrow(mtcars), 3),
dimnames = list(rownames(mtcars),
colnames(mtcars_x)))
mtcars_y <- mtcars[, "mpg"]
nn_model <- keras_model_sequential() %>%
layer_dense(units = 1, input_shape = 3, activation = "linear")
nn_model
nn_model <- keras_model_sequential() %>%
layer_dense(units = 4, input_shape = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
nn_model
nn_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.01),
loss = "mean_squared_error",
metrics = "mean_absolute_error")
nn_model_training <- nn_model %>% fit(x = mtcars_x,
y = mtcars_y,
epochs = 10000,
verbose = FALSE)
plot(nn_model_training)
get_weights(nn_model)
prediction1 <- predict(nn_model, array(c(6, 350, 125), dim = c(1, 3)))
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction1)
print(prediction2)
library(reticulate)
library(tensorflow)
library(keras)
clear_session(free_memory = TRUE)
# Chunk 1
library(reticulate)
library(tensorflow)
library(keras)
use_virtualenv("my_tf_workspace", required = TRUE)
mtcars <- mtcars
mtcars_x <- mtcars[, c("cyl", "disp", "hp")]
mtcars_x <- array(data = unlist(mtcars_x), dim = c(nrow(mtcars), 3),
dimnames = list(rownames(mtcars),
colnames(mtcars_x)))
mtcars_y <- mtcars[, "mpg"]
set.seed(42)
nn_model <- keras_model_sequential() %>%
layer_dense(units = 1, input_shape = 3, activation = "linear")
nn_model
#clear_session(free_memory = TRUE)
nn_model <- keras_model_sequential() %>%
layer_dense(units = 4, input_shape = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
nn_model
nn_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.01),
loss = "mean_squared_error",
metrics = "mean_absolute_error")
nn_model_training <- nn_model %>% fit(x = mtcars_x,
y = mtcars_y,
epochs = 10000,
verbose = FALSE)
plot(nn_model_training)
get_weights(nn_model)
prediction1 <- predict(nn_model, array(c(6, 350, 125), dim = c(1, 3)))
clear_session(free_memory = TRUE)
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction1)
print(prediction2)
# Chunk 1
library(reticulate)
library(tensorflow)
library(keras)
use_virtualenv("my_tf_workspace", required = TRUE)
mtcars <- mtcars
mtcars_x <- mtcars[, c("cyl", "disp", "hp")]
mtcars_x <- array(data = unlist(mtcars_x), dim = c(nrow(mtcars), 3),
dimnames = list(rownames(mtcars),
colnames(mtcars_x)))
mtcars_y <- mtcars[, "mpg"]
set.seed(42)
nn_model <- keras_model_sequential() %>%
layer_dense(units = 1, input_shape = 3, activation = "linear")
nn_model
#clear_session(free_memory = TRUE)
nn_model <- keras_model_sequential() %>%
layer_dense(units = 4, input_shape = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
nn_model
nn_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.01),
loss = "mean_squared_error",
metrics = "mean_absolute_error")
nn_model_training <- nn_model %>% fit(x = mtcars_x,
y = mtcars_y,
epochs = 10000,
verbose = FALSE)
plot(nn_model_training)
get_weights(nn_model)
prediction1 <- predict(nn_model, array(c(6, 350, 125), dim = c(1, 3)))
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction1)
print(prediction2)
# Chunk 1
library(reticulate)
library(tensorflow)
library(keras3)
use_virtualenv("my_tf_workspace", required = TRUE)
mtcars <- mtcars
mtcars_x <- mtcars[, c("cyl", "disp", "hp")]
mtcars_x <- array(data = unlist(mtcars_x), dim = c(nrow(mtcars), 3),
dimnames = list(rownames(mtcars),
colnames(mtcars_x)))
mtcars_y <- mtcars[, "mpg"]
set.seed(42)
nn_model <- keras_model_sequential() %>%
layer_dense(units = 1, input_shape = 3, activation = "linear")
nn_model
#clear_session(free_memory = TRUE)
nn_model <- keras_model_sequential() %>%
layer_dense(units = 4, input_shape = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
nn_model
nn_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.01),
loss = "mean_squared_error",
metrics = "mean_absolute_error")
nn_model_training <- nn_model %>% fit(x = mtcars_x,
y = mtcars_y,
epochs = 10000,
verbose = FALSE)
plot(nn_model_training)
get_weights(nn_model)
prediction1 <- predict(nn_model, array(c(6, 350, 125), dim = c(1, 3)))
prediction2 <- predict(nn_model, array(c(8, 250, 200), dim = c(1, 3)))
print(prediction1)
print(prediction2)
# Chunk 1
library(tidymodels)
library(reticulate)
library(tensorflow)
library(keras3)
library(MESS)
getwd()
setwd("C:\\Users\\steve\\OneDrive\\Documents\\School\\DSE6211\\Project")
data <- read.csv("project_data.csv")
data <- data[, -1]
data$booking_status <- ifelse(data$booking_status == "canceled", 1, 0)
#Insert feature engineering for date here
data$arrival_date <- as.Date(data$arrival_date)
data$month <- format(data$arrival_date, "%m")
data$year <- format(data$arrival_date, "%Y")
get_season <- function(month) {
month <- as.numeric(month)
if (month %in% c(12, 1, 2)) {
return("Winter")
} else if (month %in% c(3, 4, 5)) {
return("Spring")
} else if (month %in% c(6, 7, 8)) {
return("Summer")
} else if (month %in% c(9, 10, 11)) {
return("Autumn")
}
}
data$season <- sapply(data$month, get_season)
data <- data[, -9]
data <- data[, -16]
set.seed(42)
data_split <- initial_split(data, strata = "booking_status", prop = 0.75)
training_set <- training(data_split)
test_set  <- testing(data_split)
booking_recipe <-
recipe(
booking_status ~ .,
data = training_set
) %>%
step_dummy(all_nominal_predictors()) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors()) %>%
prep(training = training_set, retain = TRUE)
training_set_baked <- bake(booking_recipe, new_data = training_set)
test_set_baked <- bake(booking_recipe, new_data = test_set)
training_features <- array(data = unlist(training_set_baked[, -12]),
dim = c(nrow(training_set_baked), 28))
training_labels <- array(data = unlist(training_set_baked[, 12]),
dim = c(nrow(training_set_baked)))
test_features <- array(data = unlist(test_set_baked[, -12]),
dim = c(nrow(test_set_baked), 28))
test_labels <- array(data = unlist(test_set_baked[, 12]),
dim = c(nrow(test_set_baked)))
use_virtualenv("my_tf_workspace")
set.seed(42)
model1 <- keras_model_sequential() %>%
layer_dense(units = 87, activation = "relu") %>%
layer_dense(units = 42, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
set.seed(42)
compile(model1,
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = "accuracy")
set.seed(42)
random_shuffle <- sample(1:nrow(training_features))
training_features <- training_features[random_shuffle, ]
training_labels <- training_labels[random_shuffle]
set.seed(42)
history1 <- fit(model1, training_features, training_labels,
epochs = 250, batch_size = 512, validation_split = 0.33)
set.seed(42)
predictions1 <- predict(model1, test_features)
test_results1 <-
test_set %>%
select(booking_status) %>%
bind_cols(
data.frame(p_1 = predictions1)
)
roc_data <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data$threshold) {
over_threshold <- test_results1[test_results1$p_1 >= i, ]
fpr <- sum(over_threshold$booking_status==0)/sum(test_results1$booking_status==0)
roc_data[roc_data$threshold==i, "fpr"] <- fpr
tpr <- sum(over_threshold$booking_status==1)/sum(test_results1$booking_status==1)
roc_data[roc_data$threshold==i, "tpr"] <- tpr
}
ggplot() +
geom_line(data = roc_data, aes(x = fpr, y = tpr, color = threshold), linewidth = 2) +
scale_color_gradientn(colors = rainbow(3)) +
geom_abline(intercept = 0, slope = 1, lty = 2) +
geom_point(data = roc_data[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
geom_text(data = roc_data[seq(1, 101, 10), ],
aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2)) +
labs(title = "ROC Curve Model 1")
auc1 <- auc(x = roc_data$fpr, y = roc_data$tpr, type = "spline")
auc1
# Chunk 2
set.seed(42)
model2 <- keras_model_sequential() %>%
layer_dense(units = 174, activation = "relu") %>%
layer_dense(units = 87, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
set.seed(42)
compile(model2,
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = "accuracy")
set.seed(42)
random_shuffle <- sample(1:nrow(training_features))
training_features <- training_features[random_shuffle, ]
training_labels <- training_labels[random_shuffle]
set.seed(42)
history2 <- fit(model2, training_features, training_labels,
epochs = 250, batch_size = 512, validation_split = 0.33)
set.seed(42)
predictions2 <- predict(model2, test_features)
test_results2 <-
test_set %>%
select(booking_status) %>%
bind_cols(
data.frame(p_1 = predictions2)
)
roc_data2 <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data2$threshold) {
over_threshold <- test_results2[test_results2$p_1 >= i, ]
fpr <- sum(over_threshold$booking_status==0)/sum(test_results2$booking_status==0)
roc_data2[roc_data2$threshold==i, "fpr"] <- fpr
tpr <- sum(over_threshold$booking_status==1)/sum(test_results2$booking_status==1)
roc_data2[roc_data2$threshold==i, "tpr"] <- tpr
}
ggplot() +
geom_line(data = roc_data2, aes(x = fpr, y = tpr, color = threshold), linewidth = 2) +
scale_color_gradientn(colors = rainbow(3)) +
geom_abline(intercept = 0, slope = 1, lty = 2) +
geom_point(data = roc_data2[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
geom_text(data = roc_data2[seq(1, 101, 10), ],
aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2)) +
labs(title = "ROC Curve Model 2")
auc2 <- auc(x = roc_data2$fpr, y = roc_data2$tpr, type = "spline")
auc2
# Chunk 3
set.seed(42)
model3 <- keras_model_sequential() %>%
layer_dense(units = 87, activation = "relu") %>%
layer_dense(units = 42, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
set.seed(42)
compile(model3,
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = "accuracy")
set.seed(42)
random_shuffle <- sample(1:nrow(training_features))
training_features <- training_features[random_shuffle, ]
training_labels <- training_labels[random_shuffle]
set.seed(42)
history3 <- fit(model3, training_features, training_labels,
epochs = 750, batch_size = 512, validation_split = 0.33)
set.seed(42)
predictions3 <- predict(model3, test_features)
test_results3 <-
test_set %>%
select(booking_status) %>%
bind_cols(
data.frame(p_1 = predictions3)
)
roc_data3 <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data3$threshold) {
over_threshold <- test_results3[test_results3$p_1 >= i, ]
fpr <- sum(over_threshold$booking_status==0)/sum(test_results3$booking_status==0)
roc_data3[roc_data3$threshold==i, "fpr"] <- fpr
tpr <- sum(over_threshold$booking_status==1)/sum(test_results3$booking_status==1)
roc_data3[roc_data3$threshold==i, "tpr"] <- tpr
}
ggplot() +
geom_line(data = roc_data3, aes(x = fpr, y = tpr, color = threshold), linewidth = 2) +
scale_color_gradientn(colors = rainbow(3)) +
geom_abline(intercept = 0, slope = 1, lty = 2) +
geom_point(data = roc_data3[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
geom_text(data = roc_data3[seq(1, 101, 10), ],
aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2)) +
labs(title = "ROC Curve Model 3")
auc3 <- auc(x = roc_data3$fpr, y = roc_data3$tpr, type = "spline")
auc3
# Chunk 4
set.seed(42)
model4 <- keras_model_sequential() %>%
layer_dense(units = 87, activation = "relu") %>%
layer_dense(units = 70, activation = "relu") %>%
layer_dense(units = 53, activation = "relu") %>%
layer_dense(units = 36, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
set.seed(42)
compile(model4,
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = "accuracy")
set.seed(42)
random_shuffle <- sample(1:nrow(training_features))
training_features <- training_features[random_shuffle, ]
training_labels <- training_labels[random_shuffle]
set.seed(42)
history4 <- fit(model4, training_features, training_labels,
epochs = 250, batch_size = 512, validation_split = 0.33)
set.seed(42)
predictions4 <- predict(model4, test_features)
test_results4 <-
test_set %>%
select(booking_status) %>%
bind_cols(
data.frame(p_1 = predictions4)
)
roc_data4 <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data4$threshold) {
over_threshold <- test_results4[test_results4$p_1 >= i, ]
fpr <- sum(over_threshold$booking_status==0)/sum(test_results4$booking_status==0)
roc_data4[roc_data4$threshold==i, "fpr"] <- fpr
tpr <- sum(over_threshold$booking_status==1)/sum(test_results4$booking_status==1)
roc_data4[roc_data4$threshold==i, "tpr"] <- tpr
}
ggplot() +
geom_line(data = roc_data4, aes(x = fpr, y = tpr, color = threshold), linewidth = 2) +
scale_color_gradientn(colors = rainbow(3)) +
geom_abline(intercept = 0, slope = 1, lty = 2) +
geom_point(data = roc_data4[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
geom_text(data = roc_data4[seq(1, 101, 10), ],
aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2)) +
labs(title = "ROC Curve Model 4")
auc4 <- auc(x = roc_data4$fpr, y = roc_data4$tpr, type = "spline")
auc4
# Chunk 5
set.seed(42)
model5 <- keras_model_sequential() %>%
layer_dense(units = 87, activation = "relu") %>%
layer_dense(units = 70, activation = "relu") %>%
layer_dense(units = 53, activation = "relu") %>%
layer_dense(units = 36, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
set.seed(42)
compile(model5,
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = "accuracy")
set.seed(42)
random_shuffle <- sample(1:nrow(training_features))
training_features <- training_features[random_shuffle, ]
training_labels <- training_labels[random_shuffle]
set.seed(42)
history5 <- fit(model5, training_features, training_labels,
epochs = 750, batch_size = 512, validation_split = 0.33)
set.seed(42)
predictions5 <- predict(model5, test_features)
test_results5 <-
test_set %>%
select(booking_status) %>%
bind_cols(
data.frame(p_1 = predictions5)
)
roc_data5 <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data5$threshold) {
over_threshold <- test_results5[test_results5$p_1 >= i, ]
fpr <- sum(over_threshold$booking_status==0)/sum(test_results5$booking_status==0)
roc_data5[roc_data5$threshold==i, "fpr"] <- fpr
tpr <- sum(over_threshold$booking_status==1)/sum(test_results5$booking_status==1)
roc_data5[roc_data5$threshold==i, "tpr"] <- tpr
}
ggplot() +
geom_line(data = roc_data5, aes(x = fpr, y = tpr, color = threshold), linewidth = 2) +
scale_color_gradientn(colors = rainbow(3)) +
geom_abline(intercept = 0, slope = 1, lty = 2) +
geom_point(data = roc_data5[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
geom_text(data = roc_data5[seq(1, 101, 10), ],
aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2)) +
labs(title = "ROC Curve Model 5")
auc5 <- auc(x = roc_data5$fpr, y = roc_data5$tpr, type = "spline")
auc5
plot(history1)
title(main = "Model 1 Training and Validation Curves")
plot(history1)
plot(history2)
plot(history3)
plot(history4)
plot(history5)
