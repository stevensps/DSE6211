---
title: "Week5_SimonsenHomework"
author: "Steven Simonsen"
date: "2024-09-25"
output: pdf_document
---

```{r}
getwd()
setwd("C:\\Users\\steve\\OneDrive\\Documents\\School\\DSE6211\\Week5")

library(dplyr)
library(caret)
library(reticulate)
library(tensorflow)
library(keras3)
library(MESS)

data <- read.csv("lab_5_data.csv")

set.seed(42)
training_ind <- createDataPartition(data$lodgepole_pine,
                                    p = 0.75,
                                    list = FALSE,
                                    times = 1)

training_set <- data[training_ind, ]
test_set <- data[-training_ind, ]

top_20_soil_types <- training_set %>%
  group_by(soil_type) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  select(soil_type) %>%
  top_n(20)

training_set$soil_type <- ifelse(training_set$soil_type %in% top_20_soil_types$soil_type,
                                 training_set$soil_type,
                                 "other")

training_set$wilderness_area <- factor(training_set$wilderness_area)
training_set$soil_type <- factor(training_set$soil_type)

onehot_encoder <- dummyVars(~ wilderness_area + soil_type,
                            training_set[, c("wilderness_area", "soil_type")],
                            levelsOnly = TRUE,
                            fullRank = TRUE)


onehot_enc_training <- predict(onehot_encoder,
                               training_set[, c("wilderness_area", "soil_type")])


training_set <- cbind(training_set, onehot_enc_training)



test_set$soil_type <- ifelse(test_set$soil_type %in% top_20_soil_types$soil_type,
                             test_set$soil_type,
                             "other")


test_set$wilderness_area <- factor(test_set$wilderness_area)
test_set$soil_type <- factor(test_set$soil_type)

onehot_enc_test <- predict(onehot_encoder, test_set[, c("wilderness_area", "soil_type")])

test_set <- cbind(test_set, onehot_enc_test)

test_set[, -c(11:13)] <- scale(test_set[, -c(11:13)],
                               center = apply(training_set[, -c(11:13)], 2, mean),
                               scale = apply(training_set[, -c(11:13)], 2, sd))

training_set[, -c(11:13)] <- scale(training_set[, -c(11:13)])


training_features <- array(data = unlist(training_set[, -c(11:13)]),
                           dim = c(nrow(training_set), 33))

training_labels <- array(data = unlist(training_set[, 13]),
                         dim = c(nrow(training_set)))
                         
test_features <- array(data = unlist(test_set[, -c(11:13)]),
                       dim = c(nrow(test_set), 33))

test_labels <- array(data = unlist(test_set[, 13]),
                     dim = c(nrow(test_set)))


use_virtualenv("my_tf_workspace")

set.seed(42)
model <- keras_model_sequential() %>%
  layer_dense(units = 50, activation = "relu") %>%
  layer_dense(units = 25, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

set.seed(42)
compile(model,
        optimizer = "rmsprop",
        loss = "binary_crossentropy",
        metrics = "accuracy")

set.seed(42)
history <- fit(model, training_features, training_labels,
               epochs = 40, batch_size = 512, validation_split = 0.33)

predictions <- predict(model, test_features)

test_set$p_prob <- predictions[, 1]

head(predictions, 10)

over_threshold <- test_set[test_set$p_prob >= 0.5, ]

fpr <- sum(over_threshold$lodgepole_pine==0)/sum(test_set$lodgepole_pine==0)
fpr

tpr <- sum(over_threshold$lodgepole_pine==1)/sum(test_set$lodgepole_pine==1)
tpr

over_threshold2 <- test_set[test_set$p_prob >= 0.75, ]
fpr2 <- sum(over_threshold2$lodgepole_pine==0)/sum(test_set$lodgepole_pine==0)
fpr2

tpr2 <- sum(over_threshold2$lodgepole_pine==1)/sum(test_set$lodgepole_pine==1)
tpr2

roc_data <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)
for (i in roc_data$threshold) {
  over_threshold <- test_set[test_set$p_prob >= i, ]
  fpr <- sum(over_threshold$lodgepole_pine==0)/sum(test_set$lodgepole_pine==0)
  roc_data[roc_data$threshold==i, "fpr"] <- fpr
  tpr <- sum(over_threshold$lodgepole_pine==1)/sum(test_set$lodgepole_pine==1)
  roc_data[roc_data$threshold==i, "tpr"] <- tpr
}

ggplot() +
  geom_line(data = roc_data, aes(x = fpr, y = tpr, color = threshold), size = 2) +
  scale_color_gradientn(colors = rainbow(3)) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  geom_point(data = roc_data[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
  geom_text(data = roc_data[seq(1, 101, 10), ],
            aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2))

auc <- auc(x = roc_data$fpr, y = roc_data$tpr, type = "spline")
auc

in_interval <- test_set[test_set$p_prob >= 0.7 & test_set$p_prob <= 0.8, ]
nrow(in_interval[in_interval$lodgepole_pine==1, ])/nrow(in_interval)

set.seed(42)
calibration_data <- data.frame(bin_midpoint=seq(0.05,0.95,0.1),
                               observed_event_percentage=0)

for (i in seq(0.05,0.95,0.1)) {
  in_interval <- test_set[test_set$p_prob >= (i-0.05) & test_set$p_prob <= (i+0.05), ]
  oep <- nrow(in_interval[in_interval$lodgepole_pine==1, ])/nrow(in_interval)
  calibration_data[calibration_data$bin_midpoint==i, "observed_event_percentage"] <- oep
}

ggplot(data = calibration_data, aes(x = bin_midpoint, y = observed_event_percentage)) +
  geom_line(size = 1) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  geom_point(size = 2) +
  geom_text(aes(label = bin_midpoint), hjust = 0.75, vjust = -0.5)
```

#Exercises
1) In the ROC curve above, what is the TPR and FPR associated with the threshold value of 0.3?
```{r}
over_threshold3 <- test_set[test_set$p_prob >= 0.3, ]
fpr3 <- sum(over_threshold3$lodgepole_pine==0)/sum(test_set$lodgepole_pine==0)
fpr3

tpr3 <- sum(over_threshold3$lodgepole_pine==1)/sum(test_set$lodgepole_pine==1)
tpr3
```

2) In the calibration curve above, are the predicted probabilities in the interval (0.2, 0.3) under-confidentor over-confident?

The predicted probabilities in the interval (0.2, 0.3) are over-confident since they lie below the dotted line, which represents a well calibrated classifier. 

3) The ‘AppliedPredictiveModeling’ R package contains several datasets. One such dataset is the ‘logisticCreditPredictions’ dataframe, which contains the predictions and predicted probabilities for a credit dataset containing a binary target variable with the classes ‘Good’ and ‘Bad’. The positive class is the ‘Bad’ class, since we are trying to identify customers with bad credit. The ‘logisticCreditPredictions’ dataframe has 4 columns: the columns ‘Bad’ and ‘Good’ contain the predicted probabilities of class membership, the column ‘pred’ contains the predicted class using the threshold 0.5, and the column ‘obs’ contains the actual class. Use the code below to plot an ROC curve and calibration curve for the predicted probabilities. To do this, fill in the question marks with the appropriate column names and values. Copy and paste the ROC curve and calibration curve.

```{r}
# Hint: the column 'pred' is not needed.
# Hint: there are a total of 8 question marks.
library(AppliedPredictiveModeling)
data("logisticCreditPredictions")
lcp <- logisticCreditPredictions # only do this to shorten the name

#### ROC curve
roc_data <- data.frame(threshold=seq(1,0,-0.01), fpr=0, tpr=0)

for (i in roc_data$threshold) {
  over_threshold <- lcp[lcp$Bad >= i, ]
  fpr <- sum(over_threshold$obs=="Good")/sum(lcp$obs=="Good")
  roc_data[roc_data$threshold==i, "fpr"] <- fpr
  tpr <- sum(over_threshold$obs=="Bad")/sum(lcp$obs=="Bad")
  roc_data[roc_data$threshold==i, "tpr"] <- tpr
}
ggplot() +
geom_line(data = roc_data, aes(x = fpr, y = tpr, color = threshold), size = 2) +
scale_color_gradientn(colors = rainbow(3)) +
geom_abline(intercept = 0, slope = 1, lty = 2) +
geom_point(data = roc_data[seq(1, 101, 10), ], aes(x = fpr, y = tpr)) +
geom_text(data = roc_data[seq(1, 101, 10), ],
aes(x = fpr, y = tpr, label = threshold, hjust = 1.2, vjust = -0.2))

### calibration curve
calibration_data <- data.frame(bin_midpoint=seq(0.05,0.95,0.1),
                               observed_event_percentage=0)

for (i in seq(0.05,0.95,0.1)) {
  in_interval <- lcp[lcp$Bad >= (i-0.05) & lcp$Bad <= (i+0.05), ]
  temp <- nrow(in_interval[in_interval$obs=="Bad", ])/nrow(in_interval)
  calibration_data[calibration_data$bin_midpoint==i, "observed_event_percentage"] <-
    temp
}

ggplot(data = calibration_data, aes(x = bin_midpoint, y = observed_event_percentage)) +
  geom_line(size = 1) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  geom_point(size = 2) +
  geom_text(aes(label = bin_midpoint), hjust = 0.75, vjust = -0.5)
```




